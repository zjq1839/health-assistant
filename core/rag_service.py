"""RAG æœåŠ¡ - æ£€ç´¢å¢å¼ºç”Ÿæˆ

æ”¯æŒï¼š
1. çŸ¥è¯†åº“æ„å»ºä¸ç´¢å¼•
2. è¯­ä¹‰æ£€ç´¢
3. ä¸Šä¸‹æ–‡å¢å¼º
4. Agentic RAGå·¥ä½œæµ
"""

import os
import json
import pickle
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass
from abc import ABC, abstractmethod

import numpy as np
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.document_loaders import TextLoader, DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers.ensemble import EnsembleRetriever

from config import config as cfg
from utils.logger import logger


@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœ"""
    documents: List[Document]
    scores: List[float]
    query: str
    retrieval_method: str
    metadata: Dict[str, Any]


@dataclass
class RAGContext:
    """RAGä¸Šä¸‹æ–‡"""
    query: str
    retrieved_docs: List[Document]
    user_profile: Dict[str, Any]
    conversation_history: List[Dict[str, str]]
    domain_context: str  # nutrition, exercise, health_advice


class KnowledgeRetriever(ABC):
    """çŸ¥è¯†æ£€ç´¢å™¨æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    def retrieve(self, query: str, k: int = 5) -> RetrievalResult:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        pass
    
    @abstractmethod
    def add_documents(self, documents: List[Document]) -> None:
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        pass


class VectorKnowledgeRetriever(KnowledgeRetriever):
    """åŸºäºå‘é‡çš„çŸ¥è¯†æ£€ç´¢å™¨"""
    
    def __init__(self, embedding_model: str, knowledge_base_path: str):
        self.embedding_model = embedding_model
        self.knowledge_base_path = Path(knowledge_base_path)
        self.vector_store_path = self.knowledge_base_path / "vector_store"
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        self.embeddings = OllamaEmbeddings(model=embedding_model)
        
        # åŠ è½½æˆ–åˆ›å»ºå‘é‡å­˜å‚¨
        self.vector_store = self._load_or_create_vector_store()
        
    def _load_or_create_vector_store(self) -> FAISS:
        """åŠ è½½æˆ–åˆ›å»ºå‘é‡å­˜å‚¨"""
        if self.vector_store_path.exists():
            try:
                return FAISS.load_local(
                    str(self.vector_store_path), 
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
            except Exception as e:
                logger.warning(f"Failed to load existing vector store: {e}")
        
        # åˆ›å»ºç©ºçš„å‘é‡å­˜å‚¨
        dummy_texts = ["åˆå§‹åŒ–æ–‡æ¡£"]
        dummy_metadatas = [{"source": "init", "type": "dummy"}]
        vector_store = FAISS.from_texts(
            dummy_texts, 
            self.embeddings, 
            metadatas=dummy_metadatas
        )
        return vector_store
    
    def retrieve(self, query: str, k: int = 5) -> RetrievalResult:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        try:
            # ä½¿ç”¨ç›¸ä¼¼æ€§æœç´¢
            docs_with_scores = self.vector_store.similarity_search_with_score(query, k=k)
            
            documents = [doc for doc, score in docs_with_scores]
            scores = [float(score) for doc, score in docs_with_scores]
            
            return RetrievalResult(
                documents=documents,
                scores=scores,
                query=query,
                retrieval_method="vector_similarity",
                metadata={
                    "embedding_model": self.embedding_model,
                    "total_docs": self.vector_store.index.ntotal if hasattr(self.vector_store, 'index') else 0
                }
            )
            
        except Exception as e:
            logger.error(f"Vector retrieval failed: {e}")
            return RetrievalResult(
                documents=[],
                scores=[],
                query=query,
                retrieval_method="vector_similarity",
                metadata={"error": str(e)}
            )
    
    def add_documents(self, documents: List[Document]) -> None:
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“"""
        try:
            if not documents:
                return
                
            # æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨
            self.vector_store.add_documents(documents)
            
            # ä¿å­˜å‘é‡å­˜å‚¨
            self.vector_store.save_local(str(self.vector_store_path))
            
            logger.info(f"Added {len(documents)} documents to vector store")
            
        except Exception as e:
            logger.error(f"Failed to add documents to vector store: {e}")


class HybridKnowledgeRetriever(KnowledgeRetriever):
    """æ··åˆæ£€ç´¢å™¨ - ç»“åˆå‘é‡æ£€ç´¢å’ŒBM25"""
    
    def __init__(self, embedding_model: str, knowledge_base_path: str):
        self.knowledge_base_path = Path(knowledge_base_path)
        
        # å‘é‡æ£€ç´¢å™¨
        self.vector_retriever = VectorKnowledgeRetriever(embedding_model, knowledge_base_path)
        
        # BM25æ£€ç´¢å™¨å­˜å‚¨è·¯å¾„
        self.bm25_path = self.knowledge_base_path / "bm25_retriever.pkl"
        
        # åŠ è½½æˆ–åˆ›å»ºBM25æ£€ç´¢å™¨
        self.bm25_retriever = self._load_or_create_bm25()
        
    def _load_or_create_bm25(self) -> Optional[BM25Retriever]:
        """åŠ è½½æˆ–åˆ›å»ºBM25æ£€ç´¢å™¨"""
        if self.bm25_path.exists():
            try:
                with open(self.bm25_path, 'rb') as f:
                    return pickle.load(f)
            except Exception as e:
                logger.warning(f"Failed to load BM25 retriever: {e}")
        
        return None
    
    def retrieve(self, query: str, k: int = 5) -> RetrievalResult:
        """æ··åˆæ£€ç´¢"""
        try:
            # å‘é‡æ£€ç´¢
            vector_result = self.vector_retriever.retrieve(query, k=k)
            
            # BM25æ£€ç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            bm25_docs = []
            if self.bm25_retriever:
                try:
                    bm25_docs = self.bm25_retriever.get_relevant_documents(query)[:k]
                except Exception as e:
                    logger.warning(f"BM25 retrieval failed: {e}")
            
            # åˆå¹¶ç»“æœå¹¶å»é‡
            all_docs = vector_result.documents + bm25_docs
            unique_docs = []
            seen_content = set()
            
            for doc in all_docs:
                content_hash = hash(doc.page_content)
                if content_hash not in seen_content:
                    unique_docs.append(doc)
                    seen_content.add(content_hash)
            
            # é™åˆ¶è¿”å›æ•°é‡
            final_docs = unique_docs[:k]
            
            return RetrievalResult(
                documents=final_docs,
                scores=vector_result.scores[:len(final_docs)],
                query=query,
                retrieval_method="hybrid_vector_bm25",
                metadata={
                    "vector_docs": len(vector_result.documents),
                    "bm25_docs": len(bm25_docs),
                    "final_docs": len(final_docs)
                }
            )
            
        except Exception as e:
            logger.error(f"Hybrid retrieval failed: {e}")
            return self.vector_retriever.retrieve(query, k)
    
    def add_documents(self, documents: List[Document]) -> None:
        """æ·»åŠ æ–‡æ¡£åˆ°æ··åˆæ£€ç´¢å™¨"""
        # æ·»åŠ åˆ°å‘é‡æ£€ç´¢å™¨
        self.vector_retriever.add_documents(documents)
        
        # é‡å»ºBM25æ£€ç´¢å™¨
        try:
            if documents:
                self.bm25_retriever = BM25Retriever.from_documents(documents)
                # ä¿å­˜BM25æ£€ç´¢å™¨
                with open(self.bm25_path, 'wb') as f:
                    pickle.dump(self.bm25_retriever, f)
                logger.info(f"Updated BM25 retriever with {len(documents)} documents")
        except Exception as e:
            logger.error(f"Failed to update BM25 retriever: {e}")


class RAGService:
    """RAGæœåŠ¡ - æ£€ç´¢å¢å¼ºç”Ÿæˆ"""
    
    def __init__(self, 
                 knowledge_retriever: KnowledgeRetriever,
                 llm_service: Any):
        self.retriever = knowledge_retriever
        self.llm_service = llm_service
        
        # æ–‡æœ¬åˆ†å—å™¨
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", " ", ""]
        )
        
    def load_knowledge_base(self, knowledge_path: str) -> None:
        """åŠ è½½çŸ¥è¯†åº“"""
        knowledge_dir = Path(knowledge_path)
        if not knowledge_dir.exists():
            logger.warning(f"Knowledge directory not found: {knowledge_path}")
            return
        
        try:
            # åŠ è½½æ–‡æ¡£
            loader = DirectoryLoader(
                str(knowledge_dir),
                glob="**/*.txt",
                loader_cls=TextLoader,
                loader_kwargs={"encoding": "utf-8"}
            )
            documents = loader.load()
            
            if not documents:
                logger.warning("No documents found in knowledge directory")
                return
            
            # åˆ†å—å¤„ç†
            chunks = self.text_splitter.split_documents(documents)
            
            # æ·»åŠ åˆ°æ£€ç´¢å™¨
            self.retriever.add_documents(chunks)
            
            logger.info(f"Loaded {len(documents)} documents, {len(chunks)} chunks")
            
        except Exception as e:
            logger.error(f"Failed to load knowledge base: {e}")
    
    def retrieve_context(self, query: str, 
                        user_profile: Dict[str, Any] = None,
                        conversation_history: List[Dict[str, str]] = None,
                        domain_context: str = "general",
                        k: int = 5) -> RAGContext:
        """æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡"""
        
        print("\n" + "="*80)
        print("ğŸ” RAG æ£€ç´¢è¿‡ç¨‹å¼€å§‹")
        print("="*80)
        
        # å¢å¼ºæŸ¥è¯¢
        enhanced_query = self._enhance_query(
            query, user_profile, conversation_history, domain_context
        )
        
        print(f"ğŸ“ åŸå§‹æŸ¥è¯¢: {query}")
        print(f"ğŸ”§ å¢å¼ºæŸ¥è¯¢: {enhanced_query}")
        print(f"ğŸ¯ é¢†åŸŸä¸Šä¸‹æ–‡: {domain_context}")
        print(f"ğŸ‘¤ ç”¨æˆ·ç”»åƒ: {user_profile}")
        
        # æ£€ç´¢æ–‡æ¡£
        print(f"\nğŸ” å¼€å§‹æ£€ç´¢ç›¸å…³æ–‡æ¡£ (k={k})...")
        retrieval_result = self.retriever.retrieve(enhanced_query, k=k)
        
        print(f"âœ… æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(retrieval_result.documents)} ä¸ªç›¸å…³æ–‡æ¡£")
        print(f"ğŸ”§ æ£€ç´¢æ–¹æ³•: {retrieval_result.retrieval_method}")
        print(f"ğŸ“Š æ£€ç´¢å…ƒæ•°æ®: {retrieval_result.metadata}")
        
        # æ‰“å°æ£€ç´¢åˆ°çš„æ–‡æ¡£æ®µè½
        print("\nğŸ“– æ£€ç´¢åˆ°çš„æ–‡æ¡£æ®µè½:")
        print("-"*60)
        for i, doc in enumerate(retrieval_result.documents):
            score = retrieval_result.scores[i] if i < len(retrieval_result.scores) else "N/A"
            print(f"ğŸ“„ æ–‡æ¡£ {i+1} (ç›¸ä¼¼åº¦åˆ†æ•°: {score})")
            print(f"ğŸ“‚ æ¥æº: {doc.metadata.get('source', 'æœªçŸ¥')}")
            print(f"ğŸ“ å†…å®¹é¢„è§ˆ: {doc.page_content[:200]}...")
            if len(doc.page_content) > 200:
                print(f"   (å®Œæ•´å†…å®¹é•¿åº¦: {len(doc.page_content)} å­—ç¬¦)")
            print("-"*60)
        
        context = RAGContext(
            query=enhanced_query,
            retrieved_docs=retrieval_result.documents,
            user_profile=user_profile or {},
            conversation_history=conversation_history or [],
            domain_context=domain_context
        )
        
        print("ğŸ¯ RAG ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ")
        print("="*80)
        
        return context
    
    def generate_with_context(self, context: RAGContext) -> str:
        """åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”"""
        
        print("\n" + "="*80)
        print("ğŸ¤– RAG ç”Ÿæˆè¿‡ç¨‹å¼€å§‹")
        print("="*80)
        
        # æ„å»ºå¢å¼ºæç¤ºè¯
        print("ğŸ”§ æ­£åœ¨æ„å»ºå¢å¼ºæç¤ºè¯...")
        enhanced_prompt = self._build_enhanced_prompt(context)
        
        print(f"ğŸ“Š ä½¿ç”¨çš„æ–‡æ¡£æ•°é‡: {len(context.retrieved_docs)}")
        print(f"ğŸ¯ ç›®æ ‡é¢†åŸŸ: {context.domain_context}")
        
        # æ˜¾ç¤ºæ„å»ºçš„æç¤ºè¯ï¼ˆéƒ¨åˆ†å†…å®¹ï¼‰
        print("\nğŸ“ æ„å»ºçš„æç¤ºè¯é¢„è§ˆ:")
        print("-"*60)
        prompt_preview = enhanced_prompt[:500] + "..." if len(enhanced_prompt) > 500 else enhanced_prompt
        print(prompt_preview)
        print(f"(å®Œæ•´æç¤ºè¯é•¿åº¦: {len(enhanced_prompt)} å­—ç¬¦)")
        print("-"*60)
        
        print("\nğŸ§  æ¨¡å‹æ€è€ƒè¿‡ç¨‹:")
        print("ğŸ’­ æ­£åœ¨åˆ†ææ£€ç´¢åˆ°çš„çŸ¥è¯†...")
        print("ğŸ’­ ç»“åˆç”¨æˆ·ç”»åƒè¿›è¡Œä¸ªæ€§åŒ–...")
        print("ğŸ’­ æ•´åˆå¤šä¸ªä¿¡æ¯æº...")
        print("ğŸ’­ ç”Ÿæˆä¸“ä¸šå»ºè®®...")
        
        try:
            # ä½¿ç”¨LLMç”Ÿæˆå›ç­”
            print("\nâš™ï¸ æ­£åœ¨è°ƒç”¨LLMç”Ÿæˆå›ç­”...")
            response = self.llm_service.generate_response(enhanced_prompt, "")
            
            print(f"âœ… ç”Ÿæˆå®Œæˆï¼Œå›ç­”é•¿åº¦: {len(response)} å­—ç¬¦")
            
            # è®°å½•RAGä½¿ç”¨æƒ…å†µ
            logger.info(
                "RAG generation completed",
                extra={
                    "query": context.query,
                    "retrieved_docs": len(context.retrieved_docs),
                    "domain": context.domain_context,
                    "response_length": len(response)
                }
            )
            
            print("ğŸ¯ RAG ç”Ÿæˆè¿‡ç¨‹å®Œæˆ")
            print("="*80)
            
            return response
            
        except Exception as e:
            error_msg = f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶é‡åˆ°é—®é¢˜ï¼š{str(e)}"
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {error_msg}")
            print("="*80)
            logger.error(f"RAG generation failed: {e}")
            return error_msg
    
    def _enhance_query(self, query: str,
                      user_profile: Dict[str, Any],
                      conversation_history: List[Dict[str, str]],
                      domain_context: str) -> str:
        """å¢å¼ºæŸ¥è¯¢"""
        enhanced_parts = [query]
        
        # æ·»åŠ é¢†åŸŸä¸Šä¸‹æ–‡
        if domain_context != "general":
            enhanced_parts.append(f"é¢†åŸŸï¼š{domain_context}")
        
        # æ·»åŠ ç”¨æˆ·ç”»åƒä¿¡æ¯
        if user_profile:
            profile_info = []
            if user_profile.get('age'):
                profile_info.append(f"å¹´é¾„{user_profile['age']}å²")
            if user_profile.get('gender'):
                profile_info.append(f"{user_profile['gender']}")
            if user_profile.get('health_goal'):
                profile_info.append(f"å¥åº·ç›®æ ‡ï¼š{user_profile['health_goal']}")
            
            if profile_info:
                enhanced_parts.append("ç”¨æˆ·ç‰¹å¾ï¼š" + " ".join(profile_info))
        
        # æ·»åŠ å¯¹è¯å†å²ä¸­çš„å…³é”®ä¿¡æ¯
        if conversation_history:
            recent_topics = []
            for msg in conversation_history[-3:]:
                content = msg.get('content', '')
                if any(keyword in content for keyword in ['é¥®é£Ÿ', 'è¿åŠ¨', 'å¥åº·', 'å‡è‚¥', 'å¢é‡']):
                    recent_topics.append(content[:50])
            
            if recent_topics:
                enhanced_parts.append("æœ€è¿‘è®¨è®ºï¼š" + " ".join(recent_topics))
        
        return " ".join(enhanced_parts)
    
    def _build_enhanced_prompt(self, context: RAGContext) -> str:
        """æ„å»ºå¢å¼ºæç¤ºè¯"""
        
        # æ•´ç†æ£€ç´¢åˆ°çš„çŸ¥è¯†
        knowledge_sections = []
        for i, doc in enumerate(context.retrieved_docs[:3]):  # åªä½¿ç”¨å‰3ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£
            knowledge_sections.append(f"å‚è€ƒèµ„æ–™{i+1}ï¼š\n{doc.page_content}")
        
        knowledge_context = "\n\n".join(knowledge_sections) if knowledge_sections else "æš‚æ— ç›¸å…³å‚è€ƒèµ„æ–™"
        
        # ç”¨æˆ·ç”»åƒä¿¡æ¯
        profile_info = ""
        if context.user_profile:
            profile_parts = []
            for key, value in context.user_profile.items():
                if value:
                    profile_parts.append(f"{key}: {value}")
            if profile_parts:
                profile_info = f"\nç”¨æˆ·ä¿¡æ¯ï¼š{', '.join(profile_parts)}"
        
        # æ„å»ºå®Œæ•´æç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€åä¸“ä¸šçš„å¥åº·é¡¾é—®ã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€å®ç”¨çš„å»ºè®®ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{context.query}
{profile_info}

ç›¸å…³çŸ¥è¯†ï¼š
{knowledge_context}

è¯·æ³¨æ„ï¼š
0. ä½ çš„å»ºè®®å¿…é¡»æŒ‡å‡ºä¿¡æ¯æ¥æº
1. ä¼˜å…ˆä½¿ç”¨æä¾›çš„å‚è€ƒèµ„æ–™ä¸­çš„ä¿¡æ¯
2. ç»“åˆç”¨æˆ·çš„ä¸ªäººæƒ…å†µç»™å‡ºä¸ªæ€§åŒ–å»ºè®®
3. å¦‚æœå‚è€ƒèµ„æ–™ä¸è¶³ï¼Œè¯·è¯´æ˜


è¯·ç”¨ç®€ä½“ä¸­æ–‡å›ç­”ï¼š"""

        return prompt
    
    def add_knowledge_document(self, content: str, metadata: Dict[str, Any]) -> None:
        """æ·»åŠ å•ä¸ªçŸ¥è¯†æ–‡æ¡£"""
        doc = Document(page_content=content, metadata=metadata)
        chunks = self.text_splitter.split_documents([doc])
        self.retriever.add_documents(chunks)
        
        logger.info(f"Added knowledge document: {metadata.get('title', 'Unknown')}")


class AgenticRAGService(RAGService):
    """æ™ºèƒ½ä½“RAGæœåŠ¡ - æ”¯æŒå¤šæ­¥éª¤æ¨ç†å’Œå†³ç­–"""
    
    def __init__(self, knowledge_retriever: KnowledgeRetriever, llm_service: Any):
        super().__init__(knowledge_retriever, llm_service)
        
    def multi_step_retrieve(self, query: str, 
                          user_profile: Dict[str, Any] = None,
                          max_iterations: int = 3) -> List[RAGContext]:
        """å¤šæ­¥éª¤æ£€ç´¢ - æ ¹æ®åˆå§‹ç»“æœå†³å®šæ˜¯å¦éœ€è¦è¿›ä¸€æ­¥æ£€ç´¢"""
        
        contexts = []
        current_query = query
        
        for iteration in range(max_iterations):
            # æ£€ç´¢å½“å‰æŸ¥è¯¢
            context = self.retrieve_context(
                current_query, 
                user_profile=user_profile,
                domain_context=self._detect_domain(current_query)
            )
            contexts.append(context)
            
            # å¦‚æœæ£€ç´¢åˆ°è¶³å¤Ÿçš„ç›¸å…³æ–‡æ¡£ï¼Œåœæ­¢
            if len(context.retrieved_docs) >= 3:
                break
                
            # åˆ†æå½“å‰ç»“æœï¼Œç”Ÿæˆæ›´ç²¾ç¡®çš„æŸ¥è¯¢
            refined_query = self._refine_query_based_on_results(current_query, context)
            if refined_query == current_query:  # æ²¡æœ‰æ”¹è¿›ï¼Œåœæ­¢
                break
                
            current_query = refined_query
            logger.info(f"Refined query for iteration {iteration + 1}: {refined_query}")
        
        return contexts
    
    def _detect_domain(self, query: str) -> str:
        """æ£€æµ‹æŸ¥è¯¢æ‰€å±é¢†åŸŸ"""
        nutrition_keywords = ['é¥®é£Ÿ', 'è¥å…»', 'é£Ÿç‰©', 'å¡è·¯é‡Œ', 'è›‹ç™½è´¨', 'ç»´ç”Ÿç´ ']
        exercise_keywords = ['è¿åŠ¨', 'é”»ç‚¼', 'å¥èº«', 'è·‘æ­¥', 'åŠ›é‡è®­ç»ƒ']
        health_keywords = ['å¥åº·', 'ç–¾ç—…', 'ç—‡çŠ¶', 'é¢„é˜²', 'æ²»ç–—']
        
        if any(keyword in query for keyword in nutrition_keywords):
            return "nutrition"
        elif any(keyword in query for keyword in exercise_keywords):
            return "exercise"
        elif any(keyword in query for keyword in health_keywords):
            return "health_advice"
        else:
            return "general"
    
    def _refine_query_based_on_results(self, original_query: str, context: RAGContext) -> str:
        """åŸºäºæ£€ç´¢ç»“æœä¼˜åŒ–æŸ¥è¯¢"""
        if not context.retrieved_docs:
            # å¦‚æœæ²¡æœ‰æ£€ç´¢åˆ°æ–‡æ¡£ï¼Œå°è¯•ä½¿ç”¨æ›´ä¸€èˆ¬çš„æœ¯è¯­
            return self._generalize_query(original_query)
        
        # å¦‚æœæ£€ç´¢åˆ°çš„æ–‡æ¡£è´¨é‡ä¸é«˜ï¼Œå°è¯•ä½¿ç”¨æ›´å…·ä½“çš„æœ¯è¯­
        if all(len(doc.page_content) < 100 for doc in context.retrieved_docs):
            return self._specialize_query(original_query)
        
        return original_query
    
    def _generalize_query(self, query: str) -> str:
        """æ³›åŒ–æŸ¥è¯¢"""
        generalizations = {
            'å‡è‚¥æ–¹æ³•': 'å¥åº·å‡é‡',
            'å¢è‚Œè®­ç»ƒ': 'åŠ›é‡è®­ç»ƒ',
            'è¥å…»æ­é…': 'é¥®é£ŸæŒ‡å¯¼'
        }
        
        for specific, general in generalizations.items():
            if specific in query:
                return query.replace(specific, general)
        
        return query
    
    def _specialize_query(self, query: str) -> str:
        """ç‰¹åŒ–æŸ¥è¯¢"""
        specializations = {
            'å¥åº·': 'å¥åº·ç®¡ç†æ–¹æ³•',
            'è¿åŠ¨': 'è¿åŠ¨è®­ç»ƒè®¡åˆ’',
            'é¥®é£Ÿ': 'è¥å…»é¥®é£ŸæŒ‡å¯¼'
        }
        
        for general, specific in specializations.items():
            if general in query and specific not in query:
                return query.replace(general, specific)
        
        return query


def create_rag_service(use_hybrid: bool = True) -> RAGService:
    """åˆ›å»ºRAGæœåŠ¡å®ä¾‹"""
    
    # æ ¹æ®é…ç½®é€‰æ‹©æ£€ç´¢å™¨
    if use_hybrid:
        retriever = HybridKnowledgeRetriever(
            embedding_model=cfg.knowledge_base.embedding_model,
            knowledge_base_path=cfg.knowledge_base.path
        )
    else:
        retriever = VectorKnowledgeRetriever(
            embedding_model=cfg.knowledge_base.embedding_model,
            knowledge_base_path=cfg.knowledge_base.path
        )
    
    # åˆ›å»ºRAGæœåŠ¡ï¼ˆè¿™é‡Œéœ€è¦æ³¨å…¥LLMæœåŠ¡ï¼‰
    from core.service_container import get_container, LLMService as _LLMInterface
    container = get_container()
    llm_service = container.get(_LLMInterface)
    
    return AgenticRAGService(retriever, llm_service)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºRAGæœåŠ¡
    rag_service = create_rag_service()
    
    # åŠ è½½çŸ¥è¯†åº“
    rag_service.load_knowledge_base("/home/zjq/document/langchain_learn/rag_knowledge_base")
    
    # æµ‹è¯•æ£€ç´¢å’Œç”Ÿæˆ
    context = rag_service.retrieve_context(
        "å¦‚ä½•åˆ¶å®šå¥åº·çš„å‡è‚¥è®¡åˆ’ï¼Ÿ",
        user_profile={"age": 25, "gender": "å¥³", "health_goal": "å‡è‚¥"},
        domain_context="health_advice"
    )
    
    response = rag_service.generate_with_context(context)
    print(response)