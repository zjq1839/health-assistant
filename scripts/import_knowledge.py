#!/usr/bin/env python3
"""
çŸ¥è¯†åº“å¯¼å…¥è„šæœ¬

ç”¨é€”ï¼š
1. å°†æŒ‡å®šç›®å½•çš„æ–‡æ¡£å¯¼å…¥åˆ° RAG çŸ¥è¯†åº“
2. æ”¯æŒ LangChain å’Œ LlamaIndex ä¸¤ç§æ–¹å¼
3. æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼šPDFã€TXTã€MDã€JSON

ä½¿ç”¨æ–¹æ³•ï¼š
python scripts/import_knowledge.py --source /path/to/documents --method langchain
python scripts/import_knowledge.py --source /path/to/documents --method llamaindex
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from core.enhanced_rag_service import (
    import_knowledge_from_directory, 
    create_enhanced_rag_service,
    EnhancedDocumentLoader,
    LLAMA_INDEX_AVAILABLE
)
from utils.logger import logger
from config import config as cfg


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–é¡¹"""
    issues = []
    
    # æ£€æŸ¥åŸºæœ¬ä¾èµ–
    try:
        import langchain
        import faiss
    except ImportError as e:
        issues.append(f"Missing LangChain dependencies: {e}")
    
    # æ£€æŸ¥ PDF æ”¯æŒ
    try:
        import pypdf
    except ImportError:
        issues.append("Missing PyPDF2 for PDF support. Install: pip install pypdf")
    
    # æ£€æŸ¥ LlamaIndexï¼ˆå¯é€‰ï¼‰
    if not LLAMA_INDEX_AVAILABLE:
        issues.append("LlamaIndex not available. Install: pip install llama-index")
    
    return issues


def preview_documents(source_dir: str):
    """é¢„è§ˆæºç›®å½•ä¸­çš„æ–‡æ¡£"""
    loader = EnhancedDocumentLoader()
    source_path = Path(source_dir)
    
    if not source_path.exists():
        logger.error(f"Source directory not found: {source_dir}")
        return
    
    print(f"\nğŸ“ æ‰«æç›®å½•: {source_dir}")
    print("=" * 50)
    
    file_types = {}
    total_files = 0
    
    for file_path in source_path.rglob("*"):
        if file_path.is_file():
            ext = file_path.suffix.lower()
            if ext in loader.supported_extensions:
                file_types[ext] = file_types.get(ext, 0) + 1
                total_files += 1
                print(f"âœ“ {file_path.name}")
            else:
                print(f"âš  {file_path.name} (ä¸æ”¯æŒçš„æ ¼å¼)")
    
    print("\nğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
    for ext, count in file_types.items():
        print(f"  {ext}: {count} ä¸ªæ–‡ä»¶")
    
    print(f"\næ€»è®¡: {total_files} ä¸ªæ”¯æŒçš„æ–‡ä»¶")
    return total_files


def import_with_langchain(source_dir: str):
    """ä½¿ç”¨ LangChain æ–¹å¼å¯¼å…¥"""
    logger.info("ä½¿ç”¨ LangChain + FAISS æ–¹å¼å¯¼å…¥çŸ¥è¯†åº“...")
    
    try:
        rag_service = create_enhanced_rag_service(use_llama_index=False)
        success = rag_service.import_from_directory(source_dir)
        
        if success:
            print("âœ… LangChain å¯¼å…¥æˆåŠŸï¼")
            print(f"ğŸ“š çŸ¥è¯†åº“ä½ç½®: {cfg.knowledge_base.path}")
            print(f"ğŸ” å‘é‡å­˜å‚¨: {cfg.knowledge_base.path}/vector_store")
        else:
            print("âŒ LangChain å¯¼å…¥å¤±è´¥")
            
        return success
        
    except Exception as e:
        logger.error(f"LangChain å¯¼å…¥å¤±è´¥: {e}")
        print(f"âŒ é”™è¯¯: {e}")
        return False


def import_with_llamaindex(source_dir: str):
    """ä½¿ç”¨ LlamaIndex æ–¹å¼å¯¼å…¥"""
    if not LLAMA_INDEX_AVAILABLE:
        print("âŒ LlamaIndex æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install llama-index")
        return False
    
    logger.info("ä½¿ç”¨ LlamaIndex + FAISS æ–¹å¼å¯¼å…¥çŸ¥è¯†åº“...")
    
    try:
        rag_service = create_enhanced_rag_service(use_llama_index=True)
        rag_service.load_documents_from_directory(source_dir)
        
        print("âœ… LlamaIndex å¯¼å…¥æˆåŠŸï¼")
        print(f"ğŸ“š çŸ¥è¯†åº“ä½ç½®: {cfg.knowledge_base.path}")
        print(f"ğŸ” ç´¢å¼•å­˜å‚¨: {cfg.knowledge_base.path}/llama_index_storage")
        return True
        
    except Exception as e:
        logger.error(f"LlamaIndex å¯¼å…¥å¤±è´¥: {e}")
        print(f"âŒ é”™è¯¯: {e}")
        return False


def test_query(method: str):
    """æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½"""
    print(f"\nğŸ§ª æµ‹è¯• {method} æŸ¥è¯¢åŠŸèƒ½...")
    
    try:
        use_llama = (method == "llamaindex")
        rag_service = create_enhanced_rag_service(use_llama_index=use_llama)
        
        test_query = "ä»€ä¹ˆæ˜¯å¥åº·çš„é¥®é£Ÿä¹ æƒ¯ï¼Ÿ"
        
        if use_llama:
            result = rag_service.query(test_query)
            print(f"âœ… æŸ¥è¯¢æµ‹è¯•æˆåŠŸ")
            print(f"ğŸ” æŸ¥è¯¢: {test_query}")
            print(f"ğŸ“ ç»“æœ: {str(result)[:200]}...")
        else:
            context = rag_service.retrieve_context(test_query)
            num_chunks = len(context.retrieved_docs)
            print(f"âœ… æŸ¥è¯¢æµ‹è¯•æˆåŠŸ")
            print(f"ğŸ” æŸ¥è¯¢: {test_query}")
            print(f"ğŸ“„ æ£€ç´¢åˆ° {num_chunks} ä¸ªç›¸å…³ç‰‡æ®µ")
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")


def main():
    parser = argparse.ArgumentParser(description="RAG çŸ¥è¯†åº“å¯¼å…¥å·¥å…·")
    parser.add_argument(
        "--source", 
        required=True, 
        help="æºæ–‡æ¡£ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--method", 
        choices=["langchain", "llamaindex"], 
        default="langchain",
        help="å¯¼å…¥æ–¹æ³•: langchain æˆ– llamaindex (é»˜è®¤: langchain)"
    )
    parser.add_argument(
        "--preview", 
        action="store_true",
        help="ä»…é¢„è§ˆæ–‡æ¡£ï¼Œä¸æ‰§è¡Œå¯¼å…¥"
    )
    parser.add_argument(
        "--test", 
        action="store_true",
        help="å¯¼å…¥åæµ‹è¯•æŸ¥è¯¢åŠŸèƒ½"
    )
    parser.add_argument(
        "--check-deps", 
        action="store_true",
        help="æ£€æŸ¥ä¾èµ–é¡¹"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ä¾èµ–é¡¹
    if args.check_deps:
        print("ğŸ” æ£€æŸ¥ä¾èµ–é¡¹...")
        issues = check_dependencies()
        if issues:
            print("âš ï¸  å‘ç°é—®é¢˜:")
            for issue in issues:
                print(f"  - {issue}")
        else:
            print("âœ… æ‰€æœ‰ä¾èµ–é¡¹æ­£å¸¸")
        return
    
    # é¢„è§ˆæ–‡æ¡£
    total_files = preview_documents(args.source)
    if total_files == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„æ–‡æ¡£æ–‡ä»¶")
        return
    
    if args.preview:
        return
    
    # ç¡®è®¤å¯¼å…¥
    print(f"\nğŸ“¥ å‡†å¤‡ä½¿ç”¨ {args.method} æ–¹å¼å¯¼å…¥ {total_files} ä¸ªæ–‡ä»¶")
    confirm = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("æ“ä½œå·²å–æ¶ˆ")
        return
    
    # æ‰§è¡Œå¯¼å…¥
    if args.method == "langchain":
        success = import_with_langchain(args.source)
    else:
        success = import_with_llamaindex(args.source)
    
    # æµ‹è¯•æŸ¥è¯¢
    if success and args.test:
        test_query(args.method)
    
    if success:
        print(f"\nğŸ‰ çŸ¥è¯†åº“å¯¼å…¥å®Œæˆï¼")
        print(f"ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ RAG åŠŸèƒ½æŸ¥è¯¢è¿™äº›çŸ¥è¯†äº†")


if __name__ == "__main__":
    main()