#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœºå™¨å­¦ä¹ æ„å›¾åˆ†ç±»å™¨æ¼”ç¤ºè„šæœ¬
å±•ç¤ºæ ¸å¿ƒåŠŸèƒ½çš„ç®€åŒ–ä½¿ç”¨ç¤ºä¾‹
"""

from core.ml_intent_classifier import MLIntentClassifier, compare_models

def main():
    print("=" * 60)
    print("ğŸ¤– ç‹¬ç«‹æœºå™¨å­¦ä¹ æ„å›¾åˆ†ç±»å™¨æ¼”ç¤º")
    print("=" * 60)
    
    # 1. åˆ›å»ºå¹¶è®­ç»ƒåˆ†ç±»å™¨
    print("\nğŸ“š æ­¥éª¤1: åˆ›å»ºå¹¶è®­ç»ƒåˆ†ç±»å™¨")
    print("-" * 40)
    
    classifier = MLIntentClassifier(
        model_type='random_forest',  # ä½¿ç”¨éšæœºæ£®æ—ï¼ˆæœ€é«˜å‡†ç¡®ç‡ï¼‰
        enable_feature_engineering=True
    )
    
    print("æ­£åœ¨è®­ç»ƒæ¨¡å‹...")
    metrics = classifier.train()
    
    print(f"âœ… è®­ç»ƒå®Œæˆï¼")
    print(f"   - å‡†ç¡®ç‡: {metrics['accuracy']:.1%}")
    print(f"   - äº¤å‰éªŒè¯: {metrics['cv_mean']:.1%} Â± {metrics['cv_std']:.1%}")
    print(f"   - ç‰¹å¾æ•°é‡: {metrics['feature_count']}")
    
    # 2. å•ä¸ªæ–‡æœ¬é¢„æµ‹æ¼”ç¤º
    print("\nğŸ¯ æ­¥éª¤2: å•ä¸ªæ–‡æœ¬é¢„æµ‹æ¼”ç¤º")
    print("-" * 40)
    
    test_texts = [
        "æˆ‘ä»Šå¤©åƒäº†ä¸€ä¸ªè‹¹æœå’Œä¸€ç¢—ç±³é¥­",
        "è·‘æ­¥äº†åŠå°æ—¶ï¼Œæ„Ÿè§‰å¾ˆç´¯",
        "æŸ¥çœ‹ä¸€ä¸‹æˆ‘æœ¬å‘¨çš„è¿åŠ¨è®°å½•",
        "å¸®æˆ‘ç”Ÿæˆå¥åº·åˆ†ææŠ¥å‘Š",
        "ç»™æˆ‘ä¸€äº›å‡è‚¥çš„å»ºè®®",
        "ä»Šå¤©å¤©æ°”çœŸä¸é”™"  # æœªçŸ¥æ„å›¾
    ]
    
    for text in test_texts:
        result = classifier.predict(text)
        
        # æ ¹æ®ç½®ä¿¡åº¦æ˜¾ç¤ºä¸åŒé¢œè‰²çš„çŠ¶æ€
        if result.confidence >= 0.8:
            status = "ğŸŸ¢ é«˜ç½®ä¿¡åº¦"
        elif result.confidence >= 0.6:
            status = "ğŸŸ¡ ä¸­ç­‰ç½®ä¿¡åº¦"
        else:
            status = "ğŸ”´ ä½ç½®ä¿¡åº¦"
            
        print(f"æ–‡æœ¬: '{text}'")
        print(f"æ„å›¾: {result.intent.value} | {status} ({result.confidence:.1%})")
        print()
    
    # 3. æ‰¹é‡é¢„æµ‹æ¼”ç¤º
    print("âš¡ æ­¥éª¤3: æ‰¹é‡é¢„æµ‹æ¼”ç¤º")
    print("-" * 40)
    
    batch_texts = [
        "è®°å½•ä»Šå¤©çš„æ—©é¤",
        "æŸ¥è¯¢æ˜¨å¤©æ¶ˆè€—çš„å¡è·¯é‡Œ",
        "ç”Ÿæˆæœ¬æœˆå¥åº·æŠ¥å‘Š"
    ]
    
    print(f"æ‰¹é‡å¤„ç† {len(batch_texts)} æ¡æ–‡æœ¬...")
    batch_results = classifier.batch_predict(batch_texts)
    
    for text, result in zip(batch_texts, batch_results):
        print(f"â€¢ {text} -> {result.intent.value}")
    
    # 4. ç‰¹å¾é‡è¦æ€§åˆ†æ
    print("\nğŸ” æ­¥éª¤4: ç‰¹å¾é‡è¦æ€§åˆ†æ")
    print("-" * 40)
    
    important_features = classifier.get_feature_importance(top_n=10)
    
    print("æœ€é‡è¦çš„10ä¸ªç‰¹å¾:")
    for i, (feature, importance) in enumerate(important_features.items(), 1):
        print(f"{i:2d}. {feature:<15} ({importance:.4f})")
    
    # 5. æ¨¡å‹ä¿¡æ¯å±•ç¤º
    print("\nğŸ“Š æ­¥éª¤5: æ¨¡å‹ä¿¡æ¯")
    print("-" * 40)
    
    info = classifier.get_model_info()
    print(f"æ¨¡å‹ç±»å‹: {info['model_type']}")
    print(f"è®­ç»ƒçŠ¶æ€: {'âœ… å·²è®­ç»ƒ' if info['is_trained'] else 'âŒ æœªè®­ç»ƒ'}")
    print(f"æ”¯æŒæ„å›¾ç±»å‹: {len(info['intent_types'])} ç§")
    for intent in info['intent_types']:
        print(f"  â€¢ {intent}")
    
    # 6. æ¨¡å‹æ¯”è¾ƒï¼ˆå¯é€‰ï¼‰
    print("\nğŸ† æ­¥éª¤6: ä¸åŒç®—æ³•æ€§èƒ½æ¯”è¾ƒï¼ˆå¯é€‰ï¼‰")
    print("-" * 40)
    
    user_input = input("æ˜¯å¦è¿è¡Œæ¨¡å‹æ¯”è¾ƒï¼Ÿè¿™ä¼šèŠ±è´¹é¢å¤–æ—¶é—´ (y/n): ").lower().strip()
    
    if user_input in ['y', 'yes', 'æ˜¯', '1']:
        print("æ­£åœ¨æ¯”è¾ƒä¸åŒç®—æ³•æ€§èƒ½...")
        try:
            comparison_results = compare_models()
            
            print("\nç®—æ³•æ€§èƒ½æ’è¡Œæ¦œ:")
            # æŒ‰å‡†ç¡®ç‡æ’åº
            sorted_results = sorted(
                comparison_results.items(), 
                key=lambda x: x[1]['accuracy'], 
                reverse=True
            )
            
            for rank, (model, metrics) in enumerate(sorted_results, 1):
                medal = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else f"{rank}."
                print(f"{medal} {model:<20} å‡†ç¡®ç‡: {metrics['accuracy']:.1%}")
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹æ¯”è¾ƒå¤±è´¥: {e}")
    else:
        print("è·³è¿‡æ¨¡å‹æ¯”è¾ƒ")
    
    # 7. äº¤äº’å¼æµ‹è¯•
    print("\nğŸ® æ­¥éª¤7: äº¤äº’å¼æµ‹è¯•")
    print("-" * 40)
    print("è¾“å…¥æ–‡æœ¬æµ‹è¯•åˆ†ç±»å™¨ï¼Œè¾“å…¥ 'quit' é€€å‡º")
    
    while True:
        try:
            user_text = input("\nè¯·è¾“å…¥æµ‹è¯•æ–‡æœ¬: ").strip()
            
            if not user_text or user_text.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                break
                
            result = classifier.predict(user_text)
            
            print(f"é¢„æµ‹ç»“æœ:")
            print(f"  æ„å›¾: {result.intent.value}")
            print(f"  ç½®ä¿¡åº¦: {result.confidence:.1%}")
            print(f"  å¤„ç†æ—¶é—´: {result.processing_time:.1f}ms")
            
            # ç»™å‡ºå»ºè®®
            if result.confidence < 0.5:
                print("  ğŸ’¡ æç¤º: ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–æ–‡æœ¬è¡¨è¾¾æˆ–å¢åŠ è®­ç»ƒæ•°æ®")
            elif result.intent.value == 'unknown':
                print("  ğŸ’¡ æç¤º: æœªè¯†åˆ«æ„å›¾ï¼Œå¯èƒ½éœ€è¦æ‰©å±•è®­ç»ƒæ•°æ®")
                
        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºæµ‹è¯•")
            break
        except Exception as e:
            print(f"âŒ é¢„æµ‹é”™è¯¯: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ“ æ€»ç»“:")
    print("âœ… ç‹¬ç«‹çš„æœºå™¨å­¦ä¹ åˆ†ç±»å™¨å·²æˆåŠŸåˆ›å»º")
    print("âœ… æ”¯æŒå¤šç§ç®—æ³•å’Œç‰¹å¾å·¥ç¨‹")
    print("âœ… å…·å¤‡å®Œæ•´çš„è®­ç»ƒã€é¢„æµ‹ã€è¯„ä¼°èƒ½åŠ›")
    print("âœ… å¯ä»¥ç‹¬ç«‹ä½¿ç”¨ï¼Œä¸ä¾èµ–ç°æœ‰ä»£ç ")
    print("\nğŸ“– æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹: ml_classifier_usage.md")
    print("=" * 60)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except ImportError as e:
        print(f"âŒ ä¾èµ–åº“ç¼ºå¤±: {e}")
        print("ğŸ’¡ è¯·å…ˆå®‰è£…ä¾èµ–: pip install scikit-learn jieba numpy")
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()